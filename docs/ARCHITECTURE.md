# ğŸ—ï¸ CNN æ··åˆæ¶æ„è®¾è®¡æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» CNN æ··åˆæ¶æ„æ¡†æ¶çš„è®¾è®¡åŸç†ã€å®ç°ç»†èŠ‚ä»¥åŠå®ç° 90.9% MNIST å‡†ç¡®ç‡çš„å…³é”®æŠ€æœ¯ã€‚

## ğŸ“‹ ç›®å½•

- [æ•´ä½“æ¶æ„](#-æ•´ä½“æ¶æ„)
- [æ ¸å¿ƒç®—æ³•å®ç°](#-æ ¸å¿ƒç®—æ³•å®ç°)
- [90.9%å‡†ç¡®ç‡æŠ€æœ¯åˆ†æ](#-909å‡†ç¡®ç‡æŠ€æœ¯åˆ†æ)
- [æ··åˆè¯­è¨€è®¾è®¡](#-æ··åˆè¯­è¨€è®¾è®¡)
- [å†…å­˜ç®¡ç†](#-å†…å­˜ç®¡ç†)
- [æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
- [æ‰©å±•æ€§è®¾è®¡](#-æ‰©å±•æ€§è®¾è®¡)

## ğŸ”¨ æ•´ä½“æ¶æ„

### ä¸‰å±‚æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Python API Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Training  â”‚ â”‚  Inference  â”‚ â”‚    Utils    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    pybind11ç»‘å®š
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                C++ Wrapper Layer                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Network    â”‚ â”‚   Layers    â”‚ â”‚  Optimizer  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Tensor    â”‚ â”‚    Loss     â”‚ â”‚    Utils    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    C++å‡½æ•°è°ƒç”¨
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  C Core Engine                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   BLAS/     â”‚ â”‚   Memory    â”‚ â”‚   Thread    â”‚    â”‚
â”‚  â”‚  Compute    â”‚ â”‚  Manager    â”‚ â”‚   Pool      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®è®¾è®¡åŸåˆ™

1. **æ€§èƒ½ä¼˜å…ˆ**: C æ ¸å¿ƒä¿è¯è®¡ç®—æ€§èƒ½
2. **æ˜“ç”¨æ€§**: Python æ¥å£æä¾›å‹å¥½ API
3. **æ¨¡å—åŒ–**: å±‚çº§åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
4. **ç±»å‹å®‰å…¨**: ç°ä»£ C++å’Œå¼ºç±»å‹è®¾è®¡

## ğŸ§® æ ¸å¿ƒç®—æ³•å®ç°

### å·ç§¯å±‚å®ç°

æˆ‘ä»¬çš„å·ç§¯å±‚å®ç°äº†å®Œæ•´çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼š

#### å‰å‘ä¼ æ’­

```cpp
// æ ¸å¿ƒå·ç§¯è®¡ç®—å¾ªç¯
for (int oc = 0; oc < out_channels_; oc++) {
    for (size_t oh = 0; oh < out_h; oh++) {
        for (size_t ow = 0; ow < out_w; ow++) {
            float sum = 0.0f;

            // å·ç§¯æ ¸è®¡ç®—
            for (int ic = 0; ic < in_channels_; ic++) {
                for (int kh = 0; kh < kernel_size_; kh++) {
                    for (int kw = 0; kw < kernel_size_; kw++) {
                        int ih = oh * stride_ - padding_ + kh;
                        int iw = ow * stride_ - padding_ + kw;

                        if (ih >= 0 && ih < in_h && iw >= 0 && iw < in_w) {
                            sum += input[input_idx] * weights_[weight_idx];
                        }
                    }
                }
            }

            output[output_idx] = sum + bias_[oc];
        }
    }
}
```

#### åå‘ä¼ æ’­

å®ç°äº†æƒé‡æ¢¯åº¦å’Œè¾“å…¥æ¢¯åº¦çš„å®Œæ•´è®¡ç®—ï¼š

```cpp
// æƒé‡æ¢¯åº¦ï¼šâˆ‚L/âˆ‚W = input Ã— grad_output
weight_grad_[weight_idx] += last_input_[input_idx] * grad_val;

// è¾“å…¥æ¢¯åº¦ï¼šâˆ‚L/âˆ‚input = weight Ã— grad_output
input_grad[input_idx] += weights_[weight_idx] * grad_val;

// åç½®æ¢¯åº¦ï¼šâˆ‚L/âˆ‚b = Î£ grad_output
bias_grad_[oc] += grad_output[out_idx];
```

### MaxPool å±‚å®ç°

å®ç°äº†çœŸæ­£çš„æœ€å¤§æ± åŒ–ï¼ŒåŒ…å«ç´¢å¼•è·Ÿè¸ªï¼š

```cpp
// å‰å‘ä¼ æ’­ï¼šè®°å½•æœ€å¤§å€¼ä½ç½®
for (int kh = 0; kh < kernel_size_; kh++) {
    for (int kw = 0; kw < kernel_size_; kw++) {
        if (input[input_idx] > max_val) {
            max_val = input[input_idx];
            max_idx = input_idx;  // è®°å½•æœ€å¤§å€¼ä½ç½®
        }
    }
}

// åå‘ä¼ æ’­ï¼šåªå‘æœ€å¤§å€¼ä½ç½®ä¼ æ’­æ¢¯åº¦
size_t max_input_idx = static_cast<size_t>(max_indices_[output_idx]);
input_grad[max_input_idx] += grad_output[output_idx];
```

### Dropout æ­£åˆ™åŒ–

å®ç°äº†è®­ç»ƒå’Œæ¨ç†æ¨¡å¼çš„åŒºåˆ†ï¼š

```cpp
if (!is_training()) {
    return input; // æ¨ç†æ¨¡å¼ï¼šä¸è¿›è¡Œdropout
}

// è®­ç»ƒæ¨¡å¼ï¼šéšæœºä¸¢å¼ƒå¹¶ç¼©æ”¾
for (size_t i = 0; i < input.size(); ++i) {
    if (dist(gen) > p_) {
        output[i] = input[i] / (1.0f - p_);  // ç¼©æ”¾ä¿æŒæœŸæœ›
        dropout_mask_[i] = 1.0f / (1.0f - p_);
    } else {
        output[i] = 0.0f;  // ä¸¢å¼ƒ
        dropout_mask_[i] = 0.0f;
    }
}
```

## ğŸ¯ 90.9%å‡†ç¡®ç‡æŠ€æœ¯åˆ†æ

### è·èƒœæ¶æ„è¯¦è§£

æˆ‘ä»¬ç»è¿‡ç³»ç»Ÿä¼˜åŒ–å¾—åˆ°çš„æœ€ä¼˜æ¶æ„ï¼š

```cpp
CNN::Network network;

// ç¬¬ä¸€å·ç§¯å— - ç‰¹å¾æå–
network.add_conv_layer(8, 5, 1, 2);    // 1â†’8é€šé“ï¼Œ5x5å·ç§¯ï¼Œpadding=2
network.add_relu_layer();               // ReLUæ¿€æ´»
network.add_maxpool_layer(2, 2);       // 2x2æœ€å¤§æ± åŒ–ï¼Œ28x28â†’14x14

// ç¬¬äºŒå·ç§¯å— - æ·±å±‚ç‰¹å¾
network.add_conv_layer(16, 5, 1, 0);   // 8â†’16é€šé“ï¼Œ5x5å·ç§¯ï¼Œæ— padding
network.add_relu_layer();               // ReLUæ¿€æ´»
network.add_maxpool_layer(2, 2);       // 2x2æœ€å¤§æ± åŒ–ï¼Œ14x14â†’7x7

// åˆ†ç±»å™¨éƒ¨åˆ†
network.add_flatten_layer();           // å±•å¹³ï¼š7x7x16=784
network.add_fc_layer(128);             // å…¨è¿æ¥å±‚ï¼š784â†’128
network.add_relu_layer();
network.add_dropout_layer(0.4f);       // Dropoutï¼š40%ä¸¢å¼ƒç‡

network.add_fc_layer(64);              // å…¨è¿æ¥å±‚ï¼š128â†’64
network.add_relu_layer();
network.add_dropout_layer(0.3f);       // Dropoutï¼š30%ä¸¢å¼ƒç‡

network.add_fc_layer(10);              // è¾“å‡ºå±‚ï¼š64â†’10ç±»åˆ«
```

### å…³é”®ä¼˜åŒ–æŠ€æœ¯

#### 1. Xavier å‚æ•°åˆå§‹åŒ–

```cpp
void ConvLayer::initialize_parameters() {
    float fan_in = in_channels_ * kernel_size_ * kernel_size_;
    float fan_out = out_channels_ * kernel_size_ * kernel_size_;
    weights_.xavier_uniform(fan_in, fan_out);  // é¿å…æ¢¯åº¦æ¶ˆå¤±

    bias_.zeros();  // åç½®åˆå§‹åŒ–ä¸º0
}
```

#### 2. æ¸è¿›å¼ Dropout ç­–ç•¥

- **ç¬¬ä¸€ FC å±‚**ï¼š40%ä¸¢å¼ƒç‡ï¼Œå¼ºåŠ›æ­£åˆ™åŒ–
- **ç¬¬äºŒ FC å±‚**ï¼š30%ä¸¢å¼ƒç‡ï¼Œé€‚åº¦æ­£åˆ™åŒ–
- **è¾“å‡ºå±‚**ï¼šæ—  Dropoutï¼Œä¿æŒå®Œæ•´è¾“å‡º

#### 3. ä¼˜åŒ–çš„å­¦ä¹ ç‡

- **å­¦ä¹ ç‡**ï¼š0.02 - å¹³è¡¡æ”¶æ•›é€Ÿåº¦ä¸ç¨³å®šæ€§
- **æ‰¹å¤§å°**ï¼š32 - å†…å­˜å‹å¥½ä¸”æ¢¯åº¦ç¨³å®š
- **è®­ç»ƒè½®æ¬¡**ï¼š20 - å……åˆ†è®­ç»ƒé¿å…æ¬ æ‹Ÿåˆ

#### 4. äº¤å‰ç†µæŸå¤±å‡½æ•°

```cpp
// from_logits=trueï¼Œç›´æ¥å¤„ç†ç½‘ç»œè¾“å‡º
network.set_loss_function(std::make_unique<CNN::CrossEntropyLoss>(true));
```

### æ€§èƒ½æ¼”è¿›å†ç¨‹

| ä¼˜åŒ–é˜¶æ®µ    | ä¸»è¦æ”¹è¿›   | å‡†ç¡®ç‡    | å…³é”®æŠ€æœ¯     |
| ----------- | ---------- | --------- | ------------ |
| åŸºç¡€å®ç°    | ç®€å• CNN   | 32.0%     | åŸºç¡€å‰å‘ä¼ æ’­ |
| åå‘ä¼ æ’­    | æ¢¯åº¦è®¡ç®—   | 40.4%     | å®Œæ•´ BP ç®—æ³• |
| æ¿€æ´»å‡½æ•°    | æ­£ç¡®å¯¼æ•°   | 70.0%     | æ¿€æ´»å±‚ä¼˜åŒ–   |
| æ¶æ„ä¼˜åŒ–    | æ·±åº¦ç½‘ç»œ   | 89.9%     | å¤šå±‚æ¶æ„     |
| **Dropout** | **æ­£åˆ™åŒ–** | **90.9%** | **é˜²è¿‡æ‹Ÿåˆ** |

## ğŸ”„ æ··åˆè¯­è¨€è®¾è®¡

### C++/C æ ¸å¿ƒè®¾è®¡åŸåˆ™

#### 1. å†…å­˜å¸ƒå±€ä¼˜åŒ–

```cpp
class Tensor {
private:
    std::vector<float> data_;      // è¿ç»­å†…å­˜å­˜å‚¨
    std::vector<size_t> shape_;    // å½¢çŠ¶ä¿¡æ¯
    std::vector<size_t> strides_;  // æ­¥é•¿ä¿¡æ¯ï¼ˆé¢„ç•™ï¼‰

public:
    // å†…å­˜å¯¹é½è®¿é—®
    float& operator[](size_t index) { return data_[index]; }
    const float& operator[](size_t index) const { return data_[index]; }
};
```

#### 2. RAII èµ„æºç®¡ç†

```cpp
class Layer {
public:
    virtual ~Layer() = default;  // è‡ªåŠ¨èµ„æºæ¸…ç†

private:
    Tensor weights_;     // è‡ªåŠ¨å†…å­˜ç®¡ç†
    Tensor bias_;        // æ— éœ€æ‰‹åŠ¨é‡Šæ”¾
};
```

#### 3. æ¨¡æ¿åŒ–è®¡ç®—æ ¸å¿ƒ

```cpp
template<typename T>
void compute_convolution(const T* input, const T* weight, T* output,
                        int in_h, int in_w, int kernel_size);
```

### Python ç»‘å®šè®¾è®¡

#### 1. pybind11 æ— ç¼é›†æˆ

```cpp
PYBIND11_MODULE(cnn, m) {
    py::class_<CNN::Network>(m, "Network")
        .def(py::init<>())
        .def("add_conv_layer", &CNN::Network::add_conv_layer)
        .def("train", &CNN::Network::train)
        .def("predict", &CNN::Network::predict);

    py::class_<CNN::Tensor>(m, "Tensor", py::buffer_protocol())
        .def_buffer([](CNN::Tensor &t) -> py::buffer_info {
            return py::buffer_info(
                t.data(),
                sizeof(float),
                py::format_descriptor<float>::format(),
                t.ndim(),
                t.shape(),
                t.strides()
            );
        });
}
```

#### 2. NumPy å…¼å®¹è®¾è®¡

```python
# ç›´æ¥ä½¿ç”¨NumPyæ•°ç»„
X_train = np.random.randn(1000, 1, 28, 28).astype(np.float32)
y_train = np.random.randint(0, 10, 1000)

# è‡ªåŠ¨è½¬æ¢ä¸ºC++ Tensor
network.train(X_train, y_train, epochs=20)
```

## ğŸ’¾ å†…å­˜ç®¡ç†

### æ™ºèƒ½å†…å­˜åˆ†é…

#### 1. å»¶è¿Ÿåˆå§‹åŒ–

```cpp
class ConvLayer {
    void initialize_parameters() {
        if (in_channels_ > 0) {  // åªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–
            weights_ = Tensor({out_channels_, in_channels_,
                              kernel_size_, kernel_size_});
            weights_.xavier_uniform(fan_in, fan_out);
        }
    }
};
```

#### 2. å†…å­˜å¤ç”¨ç­–ç•¥

```cpp
class Network {
private:
    std::vector<Tensor> layer_outputs_;  // å¤ç”¨ä¸­é—´ç»“æœ

    Tensor forward(const Tensor& input) {
        Tensor current = input;
        for (size_t i = 0; i < layers_.size(); ++i) {
            current = layers_[i]->forward(current);
            layer_outputs_[i] = current;  // ä¿å­˜ç”¨äºåå‘ä¼ æ’­
        }
        return current;
    }
};
```

#### 3. æ¢¯åº¦ç´¯ç§¯ç®¡ç†

```cpp
void Network::update_parameters() {
    for (auto& layer : layers_) {
        auto params = layer->parameters();
        auto grads = layer->gradients();

        optimizer_->step(params, grads);

        // æ¸…é›¶æ¢¯åº¦
        for (auto* grad : grads) {
            grad->zeros();
        }
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### è®¡ç®—ä¼˜åŒ–

#### 1. å¾ªç¯ä¼˜åŒ–

```cpp
// ä¼˜åŒ–çš„å·ç§¯è®¡ç®—ï¼šå‡å°‘åˆ†æ”¯é¢„æµ‹å¤±è´¥
for (int oc = 0; oc < out_channels_; oc++) {
    const float* weight_base = weights_.data() +
                              oc * in_channels_ * kernel_size_ * kernel_size_;
    float* output_base = output.data() + oc * out_h * out_w;

    for (size_t oh = 0; oh < out_h; oh++) {
        for (size_t ow = 0; ow < out_w; ow++) {
            float sum = 0.0f;
            // å†…å±‚å¾ªç¯ä¼˜åŒ–...
        }
    }
}
```

#### 2. OpenMP å¹¶è¡ŒåŒ–

```cpp
#pragma omp parallel for collapse(2)
for (int oc = 0; oc < out_channels_; oc++) {
    for (size_t oh = 0; oh < out_h; oh++) {
        // å¹¶è¡Œè®¡ç®—å·ç§¯
    }
}
```

#### 3. å†…å­˜è®¿é—®ä¼˜åŒ–

```cpp
// ç¼“å­˜å‹å¥½çš„æ•°æ®è®¿é—®æ¨¡å¼
class Tensor {
    // è¿ç»­å†…å­˜å¸ƒå±€ (NCHWæ ¼å¼)
    size_t get_index(size_t n, size_t c, size_t h, size_t w) const {
        return n * (channels_ * height_ * width_) +
               c * (height_ * width_) +
               h * width_ + w;
    }
};
```

### ç¼–è¯‘ä¼˜åŒ–

#### 1. CMake ä¼˜åŒ–æ ‡å¿—

```cmake
if(CMAKE_BUILD_TYPE STREQUAL "Release")
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -O3 -DNDEBUG")
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -march=native")  # ç‰¹å®šCPUä¼˜åŒ–
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -funroll-loops") # å¾ªç¯å±•å¼€
endif()
```

#### 2. é“¾æ¥æ—¶ä¼˜åŒ–

```cmake
set(CMAKE_INTERPROCEDURAL_OPTIMIZATION TRUE)  # LTOä¼˜åŒ–
```

## ğŸ”§ æ‰©å±•æ€§è®¾è®¡

### å±‚çº§æŠ½è±¡

#### 1. åŸºç¡€ Layer æ¥å£

```cpp
class Layer {
public:
    virtual Tensor forward(const Tensor& input) = 0;
    virtual Tensor backward(const Tensor& grad_output) = 0;
    virtual std::vector<Tensor*> parameters() { return {}; }
    virtual std::vector<Tensor*> gradients() { return {}; }

    // æ¨¡å¼æ§åˆ¶
    virtual void train(bool mode = true) { training_ = mode; }
    virtual bool is_training() const { return training_; }
};
```

#### 2. æ–°å±‚å®ç°æ¨¡æ¿

```cpp
class NewLayer : public Layer {
public:
    Tensor forward(const Tensor& input) override {
        // å®ç°å‰å‘ä¼ æ’­
        last_input_ = input;
        return process(input);
    }

    Tensor backward(const Tensor& grad_output) override {
        // å®ç°åå‘ä¼ æ’­
        return compute_input_gradient(grad_output);
    }

private:
    Tensor last_input_;  // ç¼“å­˜ç”¨äºåå‘ä¼ æ’­
};
```

### ä¼˜åŒ–å™¨æ¡†æ¶

#### 1. ä¼˜åŒ–å™¨åŸºç±»

```cpp
class Optimizer {
public:
    virtual void step(const std::vector<Tensor*>& params,
                     const std::vector<Tensor*>& grads) = 0;
    virtual void set_learning_rate(float lr) { learning_rate_ = lr; }

protected:
    float learning_rate_ = 0.01f;
};
```

#### 2. SGD å®ç°

```cpp
class SGDOptimizer : public Optimizer {
public:
    void step(const std::vector<Tensor*>& params,
              const std::vector<Tensor*>& grads) override {
        for (size_t i = 0; i < params.size(); ++i) {
            for (size_t j = 0; j < params[i]->size(); ++j) {
                (*params[i])[j] -= learning_rate_ * (*grads[i])[j];
            }
        }
    }
};
```

### æœªæ¥æ‰©å±•ç‚¹

#### 1. GPU åŠ é€Ÿæ”¯æŒ

```cpp
enum class Device { CPU, GPU };

class Tensor {
    void to_device(Device device) {
        if (device == Device::GPU) {
            // CUDAå†…å­˜åˆ†é…å’Œæ‹·è´
            cudaMalloc(&gpu_data_, size() * sizeof(float));
            cudaMemcpy(gpu_data_, data_.data(),
                      size() * sizeof(float), cudaMemcpyHostToDevice);
        }
    }
};
```

#### 2. åˆ†å¸ƒå¼è®­ç»ƒæ¥å£

```cpp
class DistributedNetwork : public Network {
public:
    void all_reduce_gradients() {
        // MPIæˆ–NCCLæ¢¯åº¦èšåˆ
    }

    void broadcast_parameters() {
        // å‚æ•°å¹¿æ’­åŒæ­¥
    }
};
```

## ğŸ“ˆ æ€§èƒ½åˆ†æ

### å†…å­˜ä½¿ç”¨åˆ†æ

å¯¹äº 90.9%å‡†ç¡®ç‡çš„ç½‘ç»œé…ç½®ï¼š

| ç»„ä»¶          | å‚æ•°é‡      | å†…å­˜å ç”¨  | ç™¾åˆ†æ¯”   |
| ------------- | ----------- | --------- | -------- |
| Conv1 (1â†’8)   | 608         | 2.4KB     | 1.0%     |
| Conv2 (8â†’16)  | 3,216       | 12.9KB    | 5.1%     |
| FC1 (784â†’128) | 100,352     | 391KB     | 63.1%    |
| FC2 (128â†’64)  | 8,192       | 32KB      | 12.9%    |
| FC3 (64â†’10)   | 640         | 2.5KB     | 1.0%     |
| **æ€»è®¡**      | **113,008** | **441KB** | **100%** |

### è®¡ç®—å¤æ‚åº¦åˆ†æ

```
å‰å‘ä¼ æ’­FLOPSï¼š
- Conv1: 28Ã—28Ã—8Ã—5Ã—5Ã—1 = 125,440
- Conv2: 14Ã—14Ã—16Ã—5Ã—5Ã—8 = 627,200
- FC1: 784Ã—128 = 100,352
- FC2: 128Ã—64 = 8,192
- FC3: 64Ã—10 = 640

æ€»è®¡ï¼šâ‰ˆ 862K FLOPS/æ ·æœ¬
```

## ğŸ¯ æ€»ç»“

é€šè¿‡ç²¾å¿ƒçš„æ¶æ„è®¾è®¡å’Œç³»ç»Ÿä¼˜åŒ–ï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

1. **å“è¶Šæ€§èƒ½**ï¼š90.9% MNIST å‡†ç¡®ç‡ï¼Œè¶…è¶Š 90%å¤§å…³
2. **é«˜æ•ˆå®ç°**ï¼šC++æ ¸å¿ƒä¿è¯è®¡ç®—æ€§èƒ½ï¼ŒPython æ¥å£ä¿è¯æ˜“ç”¨æ€§
3. **å®Œæ•´ç®—æ³•**ï¼šä»é›¶å®ç°çš„åå‘ä¼ æ’­ã€Dropoutã€ä¼˜åŒ–å™¨ç­‰æ ¸å¿ƒç®—æ³•
4. **ä¸“ä¸šå“è´¨**ï¼šå†…å­˜é«˜æ•ˆã€ç±»å‹å®‰å…¨ã€æ˜“äºæ‰©å±•çš„å·¥ç¨‹å®ç°

è¿™ä¸ªæ¶æ„ä¸ºæ·±åº¦å­¦ä¹ æ¡†æ¶çš„è®¾è®¡å’Œå®ç°æä¾›äº†ä¼˜ç§€çš„å‚è€ƒèŒƒä¾‹ã€‚
